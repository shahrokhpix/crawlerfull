services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: crawler_postgres
    environment:
      POSTGRES_DB: crawler_db
      POSTGRES_USER: crawler_user
      POSTGRES_PASSWORD: ${DB_PASSWORD:-your_secure_password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-postgres.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5433:5432"
    networks:
      - crawler_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U crawler_user -d crawler_db"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: crawler_redis
    command: redis-server --appendonly yes
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    networks:
      - crawler_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Main Application
  crawler:
    build: 
      context: .
      dockerfile: ${DOCKERFILE:-Dockerfile}
      args:
        - NODE_ENV=${NODE_ENV:-production}
    container_name: crawler_app
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=crawler_db
      - DB_USER=crawler_user
      - DB_PASSWORD=${DB_PASSWORD:-your_secure_password}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PORT=3004
      - ADMIN_USERNAME=${ADMIN_USERNAME:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin123}
      - PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
      - PUPPETEER_SKIP_DOWNLOAD=true
      - PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
    ports:
      - "${PORT:-3005}:3004"
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./config:/app/config
      - ./public:/app/public
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - crawler_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3004/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Nginx Reverse Proxy (Optional)
  nginx:
    image: nginx:alpine
    container_name: crawler_nginx
    ports:
      - "8080:80"
      - "8443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./public:/var/www/html:ro
    depends_on:
      - crawler
    networks:
      - crawler_network
    restart: unless-stopped
    profiles:
      - nginx

  # PM2 Process Manager (Optional)
  pm2:
    build: 
      context: .
      dockerfile: ${DOCKERFILE:-Dockerfile}
      args:
        - NODE_ENV=${NODE_ENV:-production}
    container_name: crawler_pm2
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=crawler_db
      - DB_USER=crawler_user
      - DB_PASSWORD=${DB_PASSWORD:-your_secure_password}
    ports:
      - "${PORT:-3005}:3004"
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./config:/app/config
      - ./public:/app/public
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - crawler_network
    restart: unless-stopped
    profiles:
      - pm2

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

networks:
  crawler_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16